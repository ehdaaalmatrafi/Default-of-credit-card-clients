# -*- coding: utf-8 -*-
"""Default of credit card clients.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cc0eSx_8Y7mOPHiQK3Oo7GFcdIhYZcNc
"""

import pandas as pd
#import numpy as np
import matplotlib.pyplot as plt #Import it to plot the confusion matrix and (used for display the important feature) and all the fi
from google.colab import drive

drive.mount('/content/gdrive') 
dataset = pd.read_csv('gdrive/My Drive/ai project/(5).csv')
feature_cols=['ID','LIMIT_BAL','AGE','PAY_1','PAY_2','PAY_3','PAY_4','BILL_AMT1','BILL_AMT2','PAY_AMT1','PAY_AMT6']

print('\n-----This part of code used for describe the data and cleaning it -----\n')

#Printing the number of the duplicated data in rows without ID column to know if there is any duplicate
print('\n1)checking if there is any duplicate in data:\n')
print('>number of duplicate in dataset=\n ',dataset.duplicated(subset=['LIMIT_BAL','AGE','PAY_1','PAY_2','PAY_3','PAY_4',
                                                   'BILL_AMT1','BILL_AMT2','PAY_AMT1','PAY_AMT6','dpnm']).sum(),'\n')

#Creat 'new_data' used to store data after droping the duplicates (does not contain duplicates)
new_data=dataset.drop_duplicates(subset=['LIMIT_BAL','AGE','PAY_1','PAY_2','PAY_3','PAY_4','BILL_AMT1','BILL_AMT2','PAY_AMT1','PAY_AMT6','dpnm'])
#Checking if duplicated data did removed or not
print('>number of duplicate in dataset afetr droping=\n',new_data.duplicated().sum(),'\n')

#Specify the class and feature after droping the duplicates  
x= new_data.loc[:,feature_cols] #Specify the class
y= new_data.iloc[:,-1] #Specify the feature

# the information about the columns data (if there is null value  Or  Values ​​are not integer)
print('\n2)Information about the dataset content : \n')
dataset.info()

# Describe more information of the feature columns (min, max and mean, ...) 
print('\n3)Describe the feature data (min, max...): \n',x.describe())

# recognize Irregular data(Outliers) in the Features by using matplotlib.pyplot library
for col in x.columns: #for loop going thru the features 
    print('\n-> ',col,': feature \n')
    dataset[col].hist(bins=100,color='Pink') # histogram for display all the Features
    plt.show()

#describe the number of row for each class(0,1)  
numberOfRow=dataset['dpnm'].value_counts()
print('\n4)Display the number of row in each label:\n',numberOfRow)
numberOfRow.plot( kind="bar",rot=10, fontsize=10,cmap="Pastel1") #Plot it in bar shape 
plt.show()

print('\n5)Features column names:\n', x.columns)  #print the Features we give it to x (which what we did select by using sklearn.ensemble contain method ExtraTreesClassifier)

print('\n-----This part of code after fiting the final data to the model and the result-----\n')
from sklearn.model_selection import train_test_split  #For Split the data
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42) #take 20% of the data for testing and 80% for trainig  with random state 42

#preprocessing the data for fiting it in the model
from sklearn.preprocessing import StandardScaler 
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

#Import to the neural network to fit the data into it
from sklearn.neural_network import MLPClassifier
mlp = MLPClassifier(hidden_layer_sizes=(30), max_iter=70) #using 1 hidden layer with 30 neurons (repeat 70 time)
mlp.fit(X_train, y_train.values.ravel()) # fit data to the model
prd_y = mlp.predict(X_test) # predict the y

from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix #Import to print the classification report and confusion matrix
print("\n1)The confusion matrix: \n",  confusion_matrix(y_test,prd_y),"\n") # print confusion matrix

import seaborn as sns  # Import for showing the confusion matrix plot (represented as a percentage) 
cf_matrix=confusion_matrix(y_test,prd_y) #Store the confusion matrix in cf_matrix variable to deal with it
ax = sns.heatmap(cf_matrix/cf_matrix.sum(1), annot=True,fmt='.2%', cmap='Pastel1') #How does it look like (calculate the percentage for each class and the color)
ax.set_title('Confusion Matrix by percentage'); #title
ax.xaxis.set_ticklabels(['False','True']) 
ax.yaxis.set_ticklabels(['False','True'])
plt.show()

print('\nClassification Report: \n',classification_report(y_test,prd_y)) #print the classification report